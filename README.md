# Starting out with Software Quality Engineering
# Question 1: 

You have three Requirements Specification (RS) documents assigned to your group from the provided SRS.zip file. Your task is to convert all requirements, including functional, nonfunctional, and constraints, into text format. Then, use the NASA ARM validation tool (https://arm.laplante.io) to analyze these requirements. Generate a report and include screenshots from ARM showing micro-level indicators. As the tool provides binary indicators (good or bad), your role as an independent Business Analyst is to offer your judgment on the quality of each RS document. For instance, comment on the clarity and completeness of the requirements. Provide your judgments in a bulleted/numbered form for each RS document.

Repeat this process for all three RS documents. Finally, create a table ranking the quality of the Requirements Specification from 1 to 3, where 1 represents the highest quality, and 3 indicates the lowest quality.

As a second task, identify micro-level indicators from all three RS documents and highlight them based on the following categories:
- Imperative
- Directive
- Weak Phrases
- Options
- Continuances

Let's break down the question into simpler steps:

### Task 1: Convert and Analyze Requirements

1. **Objective:**
   - Convert all requirements (functional, non-functional, and constraints) from three Requirement Specification (RS) documents in the SRS.zip file to text format.

2. **Analysis with NASA ARM Validation Tool:**
   - Utilize the [NASA ARM validation tool](https://arm.laplante.io) to assess the quality of the converted requirements.
   - Generate a report containing screenshots for micro-level indicators.

3. **Business Analyst Judgment:**
   - Provide independent judgments on the quality of each SRS document.
     - For example, comment on understandability or completeness.
     - Use bulleted or numbered points for clarity.

4. **Quality Ranking Table:**
   - Create a table ranking the quality of the three RS documents from 1 to 3.
     - Rank 1 should indicate the highest quality, and rank 3 the lowest.

### Task 2: Identify Micro-level Indicators

1. **Objective:**
   - Identify micro-level indicators from all three SRS documents.
   - Highlight indicators based on their nature (Imperative, Directive, Weak Phrases, Options, Continuances).

2. **Micro-level Indicators:**
   - Identify and categorize micro-level indicators in the SRS documents.
     - Imperative: Clearly stated commands or requirements.
     - Directive: Instructions or guidance.
     - Weak Phrases: Ambiguous or incomplete language.
     - Options: Alternatives or choices presented.
     - Continuances: Statements indicating an ongoing action or state.

### Overall Summary:

- **Purpose:**
  - The primary goal is to assess the quality of requirements in SRS documents, using both the NASA ARM tool and independent judgment.
  
- **Organization:**
  - Complete these tasks for each of the three RS documents.

- **Deliverables:**
  - A report with screenshots from the ARM tool.
  - Independent judgments for each SRS document.
  - A quality ranking table for the three SRS documents.
  - Identified and highlighted micro-level indicators in each SRS document.

By following these steps, you will systematically evaluate the quality of the RS documents and provide a comprehensive analysis with rankings and micro-level indicators.


# Question 2:

How to test the following domain applications, and which testing techniques can be used? Explain with suitable examples and proper reasoning:

1. **Virtual Reality (VR) Applications:**
   - **Testing Techniques:**
     - **Immersive Testing:** Involves testing within the virtual environment to evaluate user experience.
     - **Performance Testing:** Assess how the application handles complex virtual scenarios.
   - **Example:** Testing a VR gaming application for user comfort and responsiveness during different in-game scenarios.

2. **Augmented Reality (AR) Applications:**
   - **Testing Techniques:**
     - **Marker-based Testing:** Validates the accuracy of augmented content placement based on markers.
     - **Environmental Testing:** Ensures proper interaction in different real-world environments.
   - **Example:** Testing an AR navigation app to verify the accurate overlay of route information onto the physical world.

3. **Image Processing Applications:**
   - **Testing Techniques:**
     - **Functional Testing:** Verifies image processing algorithms and features.
     - **Performance Testing:** Evaluates the application's processing speed with varying image sizes.
   - **Example:** Testing a medical imaging application for accurate detection of anomalies.

4. **AI-Based Applications:**
   - **Testing Techniques:**
     - **Algorithm Testing:** Validates the accuracy and efficiency of AI algorithms.
     - **Data Quality Testing:** Ensures the training data used for AI models is diverse and representative.
   - **Example:** Testing a recommendation system to verify the relevance and effectiveness of suggestions.

5. **IoT-Based Applications:**
   - **Testing Techniques:**
     - **Interoperability Testing:** Ensures seamless communication among different IoT devices.
     - **Security Testing:** Identifies vulnerabilities in data transfer and device interactions.
   - **Example:** Testing a smart home application to verify the synchronization of various connected devices.

6. **Web Applications:**
   - **Testing Techniques:**
     - **Functional Testing:** Ensures all web features work as intended.
     - **Cross-Browser Testing:** Verifies compatibility across different web browsers.
   - **Example:** Testing an e-commerce website for functionality, usability, and responsiveness.

7. **Android/iOS Applications:**
   - **Testing Techniques:**
     - **Device Fragmentation Testing:** Ensures compatibility with various devices and screen sizes.
     - **Usability Testing:** Assesses user experience on different platforms.
   - **Example:** Testing a mobile banking app for consistency in functionality and design across Android and iOS devices.

Each domain application requires a tailored testing approach based on its unique characteristics and user expectations. The testing techniques mentioned are just starting points, and a comprehensive testing strategy may involve a combination of these techniques.
